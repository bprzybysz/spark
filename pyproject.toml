[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "spark-etl-ml-pipeline"
version = "0.1.0"
authors = [
    {name = "Your Name", email = "your.email@example.com"},
]
description = "Integrated data engineering and ML pipeline with Hive, Spark, and TensorFlow"
readme = "README.md"
requires-python = "3.10"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]

[project.urls]
"Homepage" = "https://github.com/your-org/spark-etl-ml-pipeline"
"Bug Tracker" = "https://github.com/your-org/spark-etl-ml-pipeline/issues"

[tool.setuptools]
packages = ["src"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_functions = "test_*"
python_classes = "Test*"

[tool.black]
line-length = 100
target-version = ['py310']
include = '\.pyi?$'

[tool.isort]
profile = "black"
line_length = 100
multi_line_output = 3

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true

[[tool.mypy.overrides]]
module = [
    "pyspark.*",
    "confluent_kafka.*",
    "tensorflow.*",
    "pandas.*",
    "numpy.*",
]
ignore_missing_imports = true

[tool.flake8]
max-line-length = 100
exclude = [".git", "__pycache__", "build", "dist"]
ignore = ["E203", "W503"] 